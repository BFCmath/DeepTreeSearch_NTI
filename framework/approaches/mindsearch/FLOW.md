Of course. Here is a generalized breakdown of the workflow for any given **Iteration N** (where N > 1), detailing the inputs, actions, and outputs for each phase of the process.

---

### **Preamble: State at the Beginning of Iteration N**

At the start of Iteration N, the system has already completed `N-1` iterations. This means the `WebSearchGraph` object is populated with:
*   The `root` node (from Iteration 1).
*   All searcher nodes and edges created in iterations 1 through `N-1`.
*   The results (`response`, `memory`) for all searcher nodes whose tasks have finished. Some tasks from iteration `N-1` might still be running, but the system waits for them to complete before starting the Planner's turn in Iteration N.

---

### **Phase 1: Data Aggregation & Preparation**

This phase prepares the input for the Planner Agent by summarizing all knowledge gathered so far.

*   **Input:**
    *   The current state of the `WebSearchGraph` object, specifically the `graph.nodes` dictionary. This contains all previously created nodes, including the completed searcher nodes which have a `['response']` and `['memory']` key.

*   **Action/Process:**
    1.  The `MindSearchAgent`'s `forward` method calls the internal function `_generate_references_from_graph`.
    2.  This function iterates through all completed searcher nodes in `graph.nodes`.
    3.  For each searcher node, it extracts:
        *   The sub-question asked: `node['content']`
        *   The answer generated by the Searcher Agent: `node['response']['content']`
    4.  It formats these into a structured text block, typically like:
        `## {sub-question}\n\n{answer_with_citations}`
    5.  Crucially, the `_update_ref` function is called to re-index all citation markers (`[[1]]`, `[[2]]`, etc.) to ensure they are unique across the entire aggregated text.
    6.  All these formatted Q&A blocks are concatenated into a single string.

*   **Output:**
    *   An `AgentMessage` object that will be fed to the Planner's LLM. The `content` of this message is the single, large string containing all the formatted Q&A pairs from every completed search node so far.

---

### **Phase 2: Planner Agent (`MindSearchAgent`) Invocation**

This is the "thinking" phase where the master agent decides the next step based on the aggregated knowledge.

*   **Input:**
    *   The `AgentMessage` generated in Phase 1, containing the full history of questions asked and answers received.
    *   The Planner's system prompt (`GRAPH_PROMPT_EN`), which reminds it of its role as a Python programmer, the `WebSearchGraph` API, and the rules for constructing the graph.

*   **Action/Process:**
    1.  The LLM analyzes the aggregated context in light of the original user goal (stored in the `root` node).
    2.  It makes a strategic decision:
        *   **Decision A (Deepen/Refine):** If an answer from a previous search is incomplete or raises a follow-up question, the Planner decides to create new child nodes. For example, if a previous search returned a list of companies, the next step might be to search for the revenue of each company.
        *   **Decision B (Broaden):** If one branch of inquiry is complete but another parallel aspect of the original question hasn't been addressed, the Planner creates new nodes that may only depend on the `root` or other high-level nodes.
        *   **Decision C (Terminate):** If the aggregated information is now sufficient to comprehensively answer the user's original question, the Planner decides the search phase is over.
    3.  Based on the decision, the LLM generates a Python code snippet to execute that plan.

*   **Output:**
    *   An `AgentMessage` where the `content` is a Python code block wrapped in `<|action_start|><|interpreter|>` and ` ```python ... ```<|action_end|>`.
        *   For **Decision A/B**, this code will contain one or more `graph.add_node(...)` calls and corresponding `graph.add_edge(...)` calls.
        *   For **Decision C**, this code will contain a single call: `graph.add_response_node()`.

---

### **Phase 3: Execution & Searcher Agent (`SearcherAgent`) Triggering**

This phase executes the Planner's plan, kicking off the next wave of parallel searches.

*   **Input:**
    *   The Python code block generated by the Planner in Phase 2.

*   **Action/Process:**
    1.  The `ExecutionAction.run` method is invoked.
    2.  The Python code is executed via `exec()`.
    3.  This mutates the `WebSearchGraph` object in memory.
    4.  For **every `graph.add_node(node_name, node_content)` call** executed:
        a. A new, independent `SearcherAgent` instance is created.
        b. This agent is assigned its specific sub-task: to answer the `node_content` question.
        c. The `SearcherAgent`'s input is prepared:
            *   `question`: The `node_content` it was given.
            *   `topic`: The content of the `root` node.
            *   `history`: The Q&A pairs from its direct parent nodes in the graph, providing immediate context.
        d. The `SearcherAgent` begins its own ReAct-style loop (using web search tools) in a separate thread or asynchronous task.
    5.  The main `ExecutionAction.run` loop waits until all newly created `SearcherAgent` tasks (`n_active_tasks`) have completed their work.

*   **Output:**
    *   **Internal State Change:** The `graph.nodes` and `graph.adjacency_list` are updated with the new nodes and edges defined in the Planner's code.
    *   **Delayed Result:** As each `SearcherAgent` finishes its task, it populates the `['response']` and `['memory']` fields of its corresponding node within the shared `graph.nodes` dictionary. This is the final result of Iteration N.

---

### **End of Iteration N & Transition**

*   If the Planner's output was **Decision A or B**, the workflow loops back to **Phase 1** for **Iteration N+1**. The newly populated `response` fields from the searchers of Iteration N will now be included in the next data aggregation.
*   If the Planner's output was **Decision C** (`add_response_node`), the `finish_condition` is met. The iterative loop terminates, and the system proceeds to the **Final Summarization Step**, where the LLM is called one last time with the `FINAL_RESPONSE_EN` prompt to synthesize all the aggregated Q&A pairs into a single, coherent answer for the user.